\documentclass[../integ-proba.tex]{subfiles}

\begin{document}

    \chapter{Généralités sur les probabilités}

    \section{Premières définitions}

    Commençons par définir les notions fondamentales de probabilités, à l'aide du formalisme introduit dans la partie précédente.

    \begin{defi}
        On appelle \textbf{espace probabilisable} un espace mesurable, dans le contexte des probabilités.
    \end{defi}

    \begin{defi}
        Soit $\left(\Omega, \mathcal{A}\right)$ un espace probabilisable.
        Une \textbf{mesure de probabilité} (ou \textbf{loi de probabilité}) $\mathbb{P}$ sur $\left(\Omega, \mathcal{A}\right)$ est une mesure sur $\left(\Omega, \mathcal{A}\right)$, à valeurs dans $\left[0,1\right]$, telle que $\mathbb{P}\left(\Omega\right)=1$.
    \end{defi}

    \begin{defi}
        On appelle \textbf{espace probabilisé} un espace probabilisable muni d'une mesure de probabilité.
    \end{defi}

    \section{Fonction de répartition}

    La fonction de répartition est une notion qui ne concerne que les mesures de probabilités sur $\mathbb{R}$.
    La notion existe sur $\mathbb{R}^n$, mais est peu utilisée.
    Dans cette section, on se place donc sur un espace probabilisé $\left( \mathbb{R}, \mathcal{B}(\mathbb{R}), \mathbb{P} \right)$.

    \begin{defi}
        La \textbf{fonction de répartition} de $\mathbb{P}$ est :
        \begin{displaymath}
            F_{\mathbb{P}}:
            \left\{
            \begin{array}{rcl}
                \mathbb{R} & \longrightarrow & [0,1] \\
                x          & \longmapsto     & \mathbb{P}(]- \infty, x])
            \end{array}
            \right.
        \end{displaymath}
    \end{defi}

    \begin{thm}
        La fonction de répartition de $\mathbb{P}$ caractérise $\mathbb{P}$.
    \end{thm}

    \begin{rem}
        En particulier, cela implique que si deux mesures de probabilité ont la même fonction de répartition, alors elles sont égales.
    \end{rem}

    \begin{thm}[\textbf{Conditions nécessaires et suffisantes pour qu'une fonction soit une fonction de répartition}]
        \label{thm:carac_fdrep}
        Soit $F:\mathbb{R} \rightarrow \mathbb{R}$.
        $F$ est la fonction de répartition d'une mesure de probabilité $\mathbb{Q}$ sur $\left( \mathbb{R}, \mathcal{B}(\mathbb{R}) \right)$ si et seulement si les quatre conditions suivantes sont remplies :
        \begin{itemize}
            \itemb $F$ est croissante ;
            \itemb $F$ est continue à droite ;
            \itemb $\lim_{x \to -\infty} F(x) = 0$ ;
            \itemb $\lim_{x \to +\infty} F(x) = 1$.
        \end{itemize}
    \end{thm}

    \begin{prop}[\textbf{Propriétés des fonctions de répartition}]
        La fonction de répartition vérifie les résultats suivants :
        \begin{itemize}
            \itemb $F_\mathbb{P}$ admet une limite à gauche en tout $x \in \mathbb{R}$, notée $F_\mathbb{P}(x^-)$ ;
            \itemb $\mathbb{P}(]x,y]) = F_\mathbb{P}(y) - F_\mathbb{P}(x)$ ;
            \itemb $\mathbb{P}(]x,y[) = F_\mathbb{P}(y^-) - F_\mathbb{P}(x)$ ;
            \itemb $\mathbb{P}([x,y]) = F_\mathbb{P}(y) - F_\mathbb{P}(x^-)$ ;
            \itemb $\mathbb{P}([x,y[) = F_\mathbb{P}(y^-) - F_\mathbb{P}(x^-)$.
        \end{itemize}
    \end{prop}

    \begin{rem}
        En vertu du théorème~\ref{thm:carac_fdrep}, on a bien $F_\mathbb{P}(x) = F_\mathbb{P}(x^+)$, mais nous n'avons aucun résultat équivalent sur la limite à gauche (\textit{ie} sur la continuité à gauche).
        Le corollaire suivant permet néanmoins de caractériser la continuité à gauche.
    \end{rem}

    \begin{cor}[\textbf{Caractérisation de la continuité de la fonction de répartition}]
        Soit $x \in \mathbb{R}$.
        On a $\mathbb{P}(\left\{x\right\}) = F_\mathbb{P}(x) - F_\mathbb{P}(x^-)$.
        En particulier, $\mathbb{P}(\left\{x\right\}) = 0$ ssi $F_\mathbb{P}$ est continue en $x$.
    \end{cor}

    \section{Deux cas particuliers de mesures de probabilités}
    \label{sec:probas_mes_particulieres}

    Il existe un cas particulier où les mesures de probabilité sont simples à exprimer : celui où elles sont définies par une intégrale (cf.\ section~\ref{sec:mes_defi_int}).
    Il permet de grandement simplifier les calculs.

    Ce cas particulier se décline en deux, selon si la mesure considérée est celle de Lebesgue ou celle de comptage.

    \subsection{Mesures de probabilité à densité}
    \begin{defi}
        On se place sur $\mathbb{R}$ (resp. $\mathbb{R}^n$) muni de la tribu borélienne et de la mesure de Lebesgue $\lambda$.
        Soit $f$ une fonction positive et intégrable d'intégrale 1.
        Soit $\mathbb{P}\coloneqq f \lambda$.
        Alors $\mathbb{P}$ est une mesure de probabilité, et on dit alors que $\mathbb{P}$ admet une \textbf{densité}.
    \end{defi}

    \begin{rem}
        Notons que la réciproque est fausse : il existe des mesures sur $\mathbb{R}$ (resp. $\mathbb{R}^n$) qui n'admettent pas de densité.

        Par ailleurs, si une mesure de probabilité admet une densité, elle en admet une infinité.
        En effet, si une fonction $f$ convient, alors une autre fonction $g$ qui égale à $f$ presque partout convient également : il y a \textbf{unicité de la densité de probabilité à égalité presque-partout près}. %todo why

        Enfin, en pratique, pour montrer qu'une mesure de probabilité $\mathbb{P}$ est égale à une autre mesure de probabilité $\mathbb{Q}$ de densité $f$, il suffira de montrer que $\mathbb{P}$ admet elle aussi $f$ pour densité (la condition nécessaire et suffisante étant donnée par le fait que $\mathbb{P}$ admette pour densité une fonction $g$ égale $\lambda$-presque-partout à $f$).
    \end{rem}

    Voici justement un théorème qui donne une condition nécessaire et suffisante simple pour qu'une mesure de probabilité admette une certaine fonction de densité.
    C'est celle qui est utilisée en pratique (plus simple que de passer par la définition).

    \begin{thm}
        On se place sur $\mathbb{R}$ (resp. $\mathbb{R}^n$) muni de la tribu borélienne et de la mesure de Lebesgue $\lambda$.
        Soit $f$ une fonction positive et intégrable d'intégrale 1.
        Une mesure de probabilité $\mathbb{P}$ sur $\mathbb{R}$ admet $f$ comme densité ssi
        \begin{displaymath}
            \forall x \in \mathbb{R}, \mathbb{P}(]-\infty, x]) = \int_{- \infty}^x f(t)\textnormal{d}t
        \end{displaymath}
        et resp. une mesure de probabilité $\mathbb{P}$ sur $\mathbb{R}^n$ admet $f$ comme densité ssi
        \begin{displaymath}
            \forall (x_1,\ldots,x_n) \in \mathbb{R}^n, \mathbb{P}(]-\infty, x_1], \ldots, ]-\infty, x_n]) = \int_{- \infty}^{x_1} \dots \int_{- \infty}^{x_n} f(t) \textnormal{d}t
        \end{displaymath}
    \end{thm}

    \begin{prop}[\textbf{Propriétés de la fonction de répartition d'une mesure admettant une densité}]
        \label{prop:continuite_fdrep_densite}
        Soit $\mathbb{P}$ une mesure de probabilité sur $\mathbb{R}$ muni de la tribu borélienne admettant une densité $f$.
        Alors la fonction de répartition $F_\mathbb{P}$ de $\mathbb{P}$ est \textbf{continue}, \textit{ie} $\forall x \in \mathbb{R}, \mathbb{P}(\left\{ x \right\}) = 0$.
        De plus, $F_\mathbb{P}$ est dérivable en tout point $x$ où $f$ est continue, et le cas échéant $F'_\mathbb{P}(x) = f(x)$.
    \end{prop}

    \begin{prop}[\textbf{Une condition suffisante pour admettre une densité (à l'aide de la fonction de répartition)}]
        Soit $\mathbb{P}$ une mesure de probabilité sur $\mathbb{R}$ muni de la tribu borélienne.
        Si $F_\mathbb{P}$ est dérivable, alors $\mathbb{P}$ admet une densité, donnée par $F'_\mathbb{P}$.
    \end{prop}

    % TODO examples


    \subsection{Mesure de probabilité discrètes}
    Le deuxième cas particulier concerne les espaces discrets.
    Sans perte de généralité, on se place uniquement dans le cas de $\mathbb{N}$.

    On commence par énoncer le résultat important suivant :

    \begin{thm}
        Soit $\left(\mathbb{N}, \mathcal{P}(\mathbb{N}), \mathbb{P} \right)$ un espace probabilisé.
        Il existe une unique suite $f:\mathbb{N} \rightarrow \mathbb{R}$ positive et sommable de somme 1 telle que $\mathbb{P} = f c$, où $c$ est la mesure de comptage.
        De plus, $\forall n \in \mathbb{N}, f(n)=\mathbb{P}(\left\{n\right\})$, \textit{ie} :
        \begin{displaymath}
            \forall A \subset \mathbb{N}, \mathbb{P}(A) = \sum_{a \in A} \mathbb{P}(\left\{ a \right\})
        \end{displaymath}
    \end{thm}

    \begin{rem}
        Ce résultat nous prouve d'une \textbf{mesure de probabilité discrète est caractérisée par ses probabilités élémentaires} (\textit{ie} par ses valeurs sur les singletons).
        En particulier, deux mesures de probabilités discrètes sont égales si et seulement si :
        \begin{itemize}
            \itemb ce sont des mesures sur le même espace discret ;
            \itemb elles sont égales sur les probabilités élémentaires.
        \end{itemize}
        C'est la caractérisation que l'on utilisera en pratique pour vérifier que deux lois sont égales.

        Notons cependant que tout ceci est faux dans le cas général.
        Par exemple, dans le cas des mesures à densité, toutes les probabilités élémentaires sont nulles (cf.\ proposition~\ref{prop:continuite_fdrep_densite} ): il n'est donc pas possible de caractériser les lois à densité de cette manière.
    \end{rem}

    % TODO examples


\end{document}